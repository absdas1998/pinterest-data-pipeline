{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9353fd8-80eb-4dc0-89c0-107ba14e199d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8ae862c-c0ac-4fc5-8eee-c5a118f24018",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pin_file_location = \"/mnt/pinterest-data/topics/12a3410ba3cf.pin/partition=0//*.json\"\n",
    "file_type = \"json\"\n",
    "infer_schema = \"true\"\n",
    "df_pin = spark.read.format(file_type) \\\n",
    "                .option(\"inferSchema\", infer_schema) \\\n",
    "                .load(pin_file_location)\n",
    "geo_file_location = \"/mnt/pinterest-data/topics/12a3410ba3cf.geo/partition=0//*.json\"\n",
    "df_geo = spark.read.format(file_type) \\\n",
    "                 .option(\"inferSchema\", infer_schema) \\\n",
    "                 .load(geo_file_location)\n",
    "user_file_location = \"/mnt/pinterest-data/topics/12a3410ba3cf.user/partition=0//*.json\"\n",
    "df_user = spark.read.format(file_type) \\\n",
    "                  .option(\"inferSchema\", infer_schema) \\\n",
    "                  .load(user_file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cbbd977-1ee9-46ee-954c-53f462f221e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[139]: DataFrame[ind: int, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[139]: DataFrame[ind: int, unique_id: string, title: string, description: string, follower_count: int, poster_name: string, tag_list: string, is_image_or_video: string, image_src: string, save_location: string, category: string]</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pin_cleaned = df_pin.withColumn(\"category\", when(df_pin[\"category\"].isNull(), None).otherwise(df_pin[\"category\"]))\n",
    "df_pin_cleaned = df_pin.withColumn(\"description\", when(df_pin[\"description\"].isNull(), None).otherwise(df_pin[\"description\"]))\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\n",
    "    \"follower_count\",\n",
    "    when(col(\"follower_count\").endswith(\"k\"), \n",
    "         regexp_replace(col(\"follower_count\"), \"k\", \"\").cast(\"int\") * 1000)\n",
    "    .when(col(\"follower_count\").endswith(\"M\"), \n",
    "          regexp_replace(col(\"follower_count\"), \"M\", \"\").cast(\"int\") * 1000000)\n",
    "    .otherwise(col(\"follower_count\").cast(\"int\"))\n",
    ")\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\n",
    "    \"follower_count\",\n",
    "    when(\n",
    "        df_pin_cleaned[\"follower_count\"].cast(\"int\").isNotNull(),\n",
    "        df_pin_cleaned[\"follower_count\"].cast(\"int\")\n",
    "    ).otherwise(None)\n",
    ")\n",
    "df_pin_cleaned.withColumn(\"downloaded\",col(\"downloaded\").cast(\"int\"))\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\"save_location\",regexp_replace(col(\"save_location\"), \"^Local save in \", \"\"))\n",
    "df_pin_cleaned = df_pin_cleaned.withColumnRenamed(\"index\", \"ind\")\n",
    "desired_column_order = [\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \"save_location\", \"category\"]\n",
    "df_pin_cleaned = df_pin_cleaned.select(desired_column_order)\n",
    "df_pin_cleaned.withColumn(\"ind\",col(\"ind\").cast(\"int\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70a1cd2a-241e-44e5-bae6-bb390cba24d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_geo_cleaned = df_geo.withColumn(\"coordinates\", array(col(\"latitude\"), col(\"longitude\")))\n",
    "df_geo_cleaned = df_geo_cleaned.drop(\"latitude\", \"longitude\")\n",
    "df_geo_cleaned = df_geo_cleaned.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\")))\n",
    "df_geo_cleaned = df_geo_cleaned.select(\"ind\", \"country\", \"coordinates\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d2a1dad-232d-4c9a-9c64-ece1ebe4ec49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_user_cleaned = df_user.withColumn(\"user_name\", concat_ws(\" \", col(\"first_name\"), col(\"last_name\")))\n",
    "df_user_cleaned = df_user_cleaned.drop(\"first_name\", \"last_name\")\n",
    "df_user_cleaned = df_user_cleaned.withColumn(\"date_joined\", to_timestamp(col(\"date_joined\"), \"yyyy-MM-dd'T'HH:mm:ss\"))\n",
    "df_user_cleaned = df_user_cleaned.select(\"ind\", \"user_name\", \"age\", \"date_joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce3fc01a-35ea-4c79-af31-6060de7ca4bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-1644447352248796&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> df_geo_cleaned<span class=\"ansi-blue-fg\">.</span>createOrReplaceGlobalTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;geo_df&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> df_user_cleaned<span class=\"ansi-blue-fg\">.</span>createOrReplaceGlobalTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;user_df&#34;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> spark.sql(&#34;&#34;&#34;\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">      6</span> SELECT\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>    g<span class=\"ansi-blue-fg\">.</span>country<span class=\"ansi-blue-fg\">,</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: geo_df; line 7 pos 3;\n",
       "&#39;UnresolvedHaving (&#39;category_count = &#39;MAX(&#39;category_count))\n",
       "+- &#39;Aggregate [&#39;g.country, &#39;p.category], [&#39;g.country, &#39;p.category, count(1) AS category_count#7589298L]\n",
       "   +- &#39;Join Inner, (&#39;g.ind = &#39;p.ind)\n",
       "      :- &#39;SubqueryAlias g\n",
       "      :  +- &#39;UnresolvedRelation [geo_df], [], false\n",
       "      +- &#39;SubqueryAlias p\n",
       "         +- &#39;UnresolvedRelation [pin_df], [], false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-1644447352248796&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> df_geo_cleaned<span class=\"ansi-blue-fg\">.</span>createOrReplaceGlobalTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;geo_df&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> df_user_cleaned<span class=\"ansi-blue-fg\">.</span>createOrReplaceGlobalTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;user_df&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 5</span><span class=\"ansi-red-fg\"> spark.sql(&#34;&#34;&#34;\n</span><span class=\"ansi-green-intense-fg ansi-bold\">      6</span> SELECT\n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span>    g<span class=\"ansi-blue-fg\">.</span>country<span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansi-cyan-fg\">sql</span><span class=\"ansi-blue-fg\">(self, sqlQuery)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    775</span>         <span class=\"ansi-blue-fg\">[</span>Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row1&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row2&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> Row<span class=\"ansi-blue-fg\">(</span>f1<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-cyan-fg\">3</span><span class=\"ansi-blue-fg\">,</span> f2<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#39;row3&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    776</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 777</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jsparkSession<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span>sqlQuery<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>_wrapped<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    778</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    779</span>     <span class=\"ansi-green-fg\">def</span> table<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> tableName<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    121</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 123</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> converted <span class=\"ansi-green-fg\">from</span> <span class=\"ansi-green-fg\">None</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    124</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: geo_df; line 7 pos 3;\n&#39;UnresolvedHaving (&#39;category_count = &#39;MAX(&#39;category_count))\n+- &#39;Aggregate [&#39;g.country, &#39;p.category], [&#39;g.country, &#39;p.category, count(1) AS category_count#7589298L]\n   +- &#39;Join Inner, (&#39;g.ind = &#39;p.ind)\n      :- &#39;SubqueryAlias g\n      :  +- &#39;UnresolvedRelation [geo_df], [], false\n      +- &#39;SubqueryAlias p\n         +- &#39;UnresolvedRelation [pin_df], [], false\n</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">AnalysisException</span>: Table or view not found: geo_df; line 7 pos 3;",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the most popular Pinterest category people post to based on their country\n",
    "df_pin_cleaned.createOrReplaceGlobalTempView(\"pin_df\")\n",
    "df_geo_cleaned.createOrReplaceGlobalTempView(\"geo_df\")\n",
    "df_user_cleaned.createOrReplaceGlobalTempView(\"user_df\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "   g.country,\n",
    "   p.category,\n",
    "   COUNT(*) AS category_count\n",
    "FROM\n",
    "   geo_df g\n",
    "JOIN\n",
    "   pin_df p\n",
    "ON\n",
    "   g.ind = p.ind\n",
    "GROUP BY\n",
    "   g.country,\n",
    "   p.category\n",
    "HAVING\n",
    "   category_count = MAX(category_count)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbda28b1-a115-4fb5-9a9c-10962d997bb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clean_and_analyse_pinterest_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
